{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1504ece8-05ec-4bd3-9a3e-20d71e001e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting refractml\n",
      "  Using cached https://files.pythonhosted.org/packages/f9/0d/023d845cf453feb632b08435c91f7e5d050c0df73c5be66bdbbca2f6ba87/refractml-1.0.3-py2.py3-none-any.whl\n",
      "Collecting requests-toolbelt==0.9.1\n",
      "  Using cached https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl\n",
      "Collecting urllib3==1.26.15\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl\n",
      "Collecting PyYAML==6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/12/fc/a4d5a7554e0067677823f7265cb3ae22aed8a238560b5133b58cda252dad/PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting mosaic-utils\n",
      "  Using cached https://files.pythonhosted.org/packages/09/d7/8424b1dcaa5b1a2f824fc440aa1c4ef45e0bf6593d11b37962311614f365/mosaic_utils-1.0.2-py2.py3-none-any.whl\n",
      "Collecting cloudpickle==1.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Processing /home/mosaic-ai/.cache/pip/wheels/ab/d0/0e/613976a1b51b5654859e2a82ade64329859bce431e280f2a39/shutils-0.1.0-cp39-none-any.whl\n",
      "Collecting requests<3.0.0,>=2.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting scikit-learn==1.2.1; python_version >= \"3.8\"\n",
      "  Using cached https://files.pythonhosted.org/packages/de/5b/a3ee68c28dde18b9b744124c7e1701b8e5d588c8b0ef44d233864a97cffc/scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting pymysql\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl\n",
      "Collecting configparser\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/20/f4aab9a42378542295c3be2bbdab353de10eb95396f6d4a5bc7a21b00952/configparser-7.0.0-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/e2/4dea6313ef2b38442fccbbaf4017e50a6c3c8a50e8ee9b512783e5c90409/joblib-1.4.0-py3-none-any.whl\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/ba/a778e6c0020d728c119b0379805a357135fe8c9bc87fdb7e0750ca11319f/scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/84/ccd9b08653022b7785b6e3ee070ffb2825841e0dc119be22f0840b2b35cb/threadpoolctl-3.4.0-py3-none-any.whl\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement cloudpickle>=2.0.0, but you'll have cloudpickle 1.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement pandas<2,>=1.0.0, but you'll have pandas 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement snowflake-snowpark-python<2,>=1.5.1, but you'll have snowflake-snowpark-python 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.25.3 has requirement jsonschema>=4.18.0, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, certifi, charset-normalizer, idna, requests, requests-toolbelt, PyYAML, joblib, numpy, scipy, threadpoolctl, scikit-learn, mosaic-utils, cloudpickle, pymysql, configparser, shutils, refractml\n",
      "Successfully installed PyYAML-6.0 certifi-2024.2.2 charset-normalizer-3.3.2 cloudpickle-1.6.0 configparser-7.0.0 idna-3.7 joblib-1.4.0 mosaic-utils-1.0.2 numpy-1.26.4 pymysql-1.1.0 refractml-1.0.3 requests-2.31.0 requests-toolbelt-0.9.1 scikit-learn-1.2.1 scipy-1.13.0 shutils-0.1.0 threadpoolctl-3.4.0 urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt-0.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-1.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pymysql already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/PyMySQL-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/backports already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/configparser-7.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils-0.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/refractml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/refractml-1.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231487ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/mosaic-ai/.cache/pip/wheels/b3/bb/a5/302c9622d3602de5a21831e14edffa65fb36ecb1c71ebd2a7f/pyspark-3.5.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7\n",
      "  Using cached https://files.pythonhosted.org/packages/10/30/a58b32568f1623aaad7db22aa9eafc4c6c194b429ff35bdc55ca2726da47/py4j-0.10.9.7-py2.py3-none-any.whl\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/py4j already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/py4j-0.10.9.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pyspark already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pyspark-3.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc80f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "Collecting urllib3==1.26.15\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: jupyterlab-server 2.25.3 has requirement jsonschema>=4.18.0, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3\n",
      "Successfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420f2dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: urllib3\n",
      "Version: 1.26.15\n",
      "Summary: HTTP library with thread-safe connection pooling, file post, and more.\n",
      "Home-page: https://urllib3.readthedocs.io/\n",
      "Author: Andrey Petrov\n",
      "Author-email: andrey.petrov@shazow.net\n",
      "License: MIT\n",
      "Location: /tmp/pip_packages\n",
      "Requires: \n",
      "Required-by: requests, refractml, snowflake-connector-python, botocore\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c57b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c82e7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "from snowflake.snowpark.session import Session\n",
    "import configparser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"snowflake_connection_new.ini\")\n",
    "\n",
    "connection_parameters = {\n",
    "    \"user\": f'{config[\"Snowflake\"][\"user\"]}',\n",
    "    \"password\": f'{config[\"Snowflake\"][\"password\"]}',\n",
    "    \"account\": f'{config[\"Snowflake\"][\"account\"]}',\n",
    "    \"WAREHOUSE\": f'{config[\"Snowflake\"][\"WAREHOUSE\"]}',\n",
    "    \"DATABASE\": f'{config[\"Snowflake\"][\"DATABASE\"]}',\n",
    "    \"SCHEMA\": f'{config[\"Snowflake\"][\"SCHEMA\"]}'\n",
    "}\n",
    "\n",
    "def snowflake_connector(conn):\n",
    "    try:\n",
    "        session = Session.builder.configs(conn).create()\n",
    "        print(\"connection successful!\")\n",
    "    except:\n",
    "        raise ValueError(\"error while connecting with db\")\n",
    "    return session\n",
    "\n",
    "session = snowflake_connector(connection_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3e8dcd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkFetchDataException",
     "evalue": "(1406): Failed to fetch a Pandas Dataframe. The error is: 255002: Optional dependency: 'pandas' is not installed, please see the following link for install instructions: https://docs.snowflake.com/en/user-guide/python-connector-pandas.html#installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:405\u001b[0m, in \u001b[0;36mServerConnection._to_data_or_iter\u001b[0;34m(self, results_cursor, to_pandas, to_iter)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     data_or_iter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    398\u001b[0m             functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    399\u001b[0m                 _fix_pandas_df_integer, results_cursor\u001b[38;5;241m=\u001b[39mresults_cursor\n\u001b[1;32m    400\u001b[0m             ),\n\u001b[1;32m    401\u001b[0m             results_cursor\u001b[38;5;241m.\u001b[39mfetch_pandas_batches(),\n\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m to_iter\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m _fix_pandas_df_integer(\n\u001b[0;32m--> 405\u001b[0m             \u001b[43mresults_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_pandas_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, results_cursor\n\u001b[1;32m    406\u001b[0m         )\n\u001b[1;32m    407\u001b[0m     )\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotSupportedError:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/cursor.py:1374\u001b[0m, in \u001b[0;36mSnowflakeCursor.fetch_pandas_all\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch Pandas dataframes in batches, where 'batch' refers to Snowflake Chunk.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_can_use_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/cursor.py:1279\u001b[0m, in \u001b[0;36mSnowflakeCursor.check_can_use_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m errno \u001b[38;5;241m=\u001b[39m ER_NO_PYARROW\n\u001b[0;32m-> 1279\u001b[0m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mProgrammingError\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmsg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merrno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43merrno\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 255002: Optional dependency: 'pandas' is not installed, please see the following link for install instructions: https://docs.snowflake.com/en/user-guide/python-connector-pandas.html#installation",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSnowparkFetchDataException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sales_bangalore_2022 \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSALES_MELBOURNE_COMBINED\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/telemetry.py:139\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 139\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    141\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    143\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    144\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/dataframe.py:765\u001b[0m, in \u001b[0;36mDataFrame.to_pandas\u001b[0;34m(self, statement_params, block, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;129m@df_collect_api_telemetry\u001b[39m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_pandas\u001b[39m(\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    746\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, AsyncJob]:\n\u001b[1;32m    747\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m    Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m    `Pandas DataFrame <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html>`_.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m        :func:`Session.sql` can only be a SELECT statement.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AsyncResultType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPANDAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_TWO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# if the returned result is not a pandas dataframe, raise Exception\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# this might happen when calling this method with non-select commands\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# e.g., session.sql(\"create ...\").to_pandas()\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:442\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_in_stored_procedure() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 442\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:110\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    112\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:550\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    549\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 550\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    564\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    565\u001b[0m )\n\u001b[1;32m    566\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdescription\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:102\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m     99\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:96\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m     99\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    100\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:373\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_data_or_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults_cursor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_cursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_iter\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncJob(\n\u001b[1;32m    378\u001b[0m         results_cursor[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueryId\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    379\u001b[0m         query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    386\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:415\u001b[0m, in \u001b[0;36mServerConnection._to_data_or_iter\u001b[0;34m(self, results_cursor, to_pandas, to_iter)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_FAILED_FETCH_PANDAS(\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28mstr\u001b[39m(ex)\n\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     data_or_iter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28miter\u001b[39m(results_cursor) \u001b[38;5;28;01mif\u001b[39;00m to_iter \u001b[38;5;28;01melse\u001b[39;00m results_cursor\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    421\u001b[0m     )\n",
      "\u001b[0;31mSnowparkFetchDataException\u001b[0m: (1406): Failed to fetch a Pandas Dataframe. The error is: 255002: Optional dependency: 'pandas' is not installed, please see the following link for install instructions: https://docs.snowflake.com/en/user-guide/python-connector-pandas.html#installation"
     ]
    }
   ],
   "source": [
    "sales_bangalore_2022 = session.table(\"SALES_MELBOURNE_COMBINED\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d078ce51",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Table object has no attribute head",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msales_bangalore_2022\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/dataframe.py:910\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# Snowflake DB ignores cases when there is no quotes.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [c\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]:\n\u001b[0;32m--> 910\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         )\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Table object has no attribute head"
     ]
    }
   ],
   "source": [
    "sales_bangalore_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bf5b9c-baaa-4989-ae20-d524978bd12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>frequencym</th>\n",
       "      <th>sales_value_avg</th>\n",
       "      <th>sales_units_avg</th>\n",
       "      <th>sales_indicator</th>\n",
       "      <th>scheme_amount_perproduct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD0002-OL10330</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id  frequencym  sales_value_avg  sales_units_avg  \\\n",
       "0  PRD0002-OL10330         0.6         0.004323         0.000404   \n",
       "\n",
       "   sales_indicator  scheme_amount_perproduct  \n",
       "0                1                  0.000465  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final = pd.read_csv('/data/train_data_model.csv')\n",
    "train_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acde1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = sales_bangalore_2022.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6c06d7-0caa-4766-918a-694f663cce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = sales_bangalore_2022.copy()\n",
    "master_data['trans_date'] = pd.to_datetime(master_data['trans_date'],format = '%m/%d/%Y')\n",
    "master_data['start_date'] = pd.to_datetime(master_data['start_date'],format = '%m/%d/%Y')\n",
    "master_data['mnth_code'] = pd.to_numeric(master_data['month_code'],errors ='coerce').astype(int)\n",
    "df1=master_data.copy\n",
    "master_data['unique_id']=master_data['product_code']+'-'+ master_data['outlet_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf07c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b744d1-04d9-4ffb-9f0d-c162e0c67595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_final[['frequencym','sales_value_avg','scheme_amount_perproduct']],train_final['sales_indicator'],test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce09a01-710f-414f-8f8c-f9ecc92b0dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66778068, 0.33221932],\n",
       "       [0.8336751 , 0.1663249 ],\n",
       "       [0.44592937, 0.55407063],\n",
       "       ...,\n",
       "       [0.66800724, 0.33199276],\n",
       "       [0.83363294, 0.16636706],\n",
       "       [0.6676696 , 0.3323304 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logreg.pkl', 'rb') as model_file:\n",
    "   loaded_model = pickle.load(model_file)\n",
    "probs = loaded_model.predict_proba(X_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba2c290-329c-42e1-a289-81f67bf73111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70     30799\n",
      "           1       0.57      0.82      0.68     20399\n",
      "\n",
      "    accuracy                           0.69     51198\n",
      "   macro avg       0.70      0.71      0.69     51198\n",
      "weighted avg       0.73      0.69      0.69     51198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cutoff = 0.3\n",
    "y_pred = (probs[:,1]>=cutoff).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f641cd-cce4-4839-97e8-234709519d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.read_csv('/data/test_set_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970be2f6-8bd9-430c-b555-6420ec5cf729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189082, 3) (189082,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>frequencym</th>\n",
       "      <th>sales_value_avg</th>\n",
       "      <th>sales_units_avg</th>\n",
       "      <th>sales_indicator</th>\n",
       "      <th>scheme_amount_perproduct</th>\n",
       "      <th>probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD0002-OL10330</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.807117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD0002-OL10346</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD0002-OL10347</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.298690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD0002-OL10358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.950099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD0002-OL10386</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.899377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189077</th>\n",
       "      <td>PRD0168-OL97586</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189078</th>\n",
       "      <td>PRD0168-OL97590</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189079</th>\n",
       "      <td>PRD0168-OL97602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.165792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189080</th>\n",
       "      <td>PRD0168-OL97615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.477312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189081</th>\n",
       "      <td>PRD0168-OL97618</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.476894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189082 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id  frequencym  sales_value_avg  sales_units_avg  \\\n",
       "0       PRD0002-OL10330    0.666667         0.004323         0.000404   \n",
       "1       PRD0002-OL10346    0.166667         0.001430         0.000135   \n",
       "2       PRD0002-OL10347    0.166667         0.001767         0.000168   \n",
       "3       PRD0002-OL10358    1.000000         0.015771         0.001481   \n",
       "4       PRD0002-OL10386    0.833333         0.008417         0.000791   \n",
       "...                 ...         ...              ...              ...   \n",
       "189077  PRD0168-OL97586    0.166667         0.001948         0.000303   \n",
       "189078  PRD0168-OL97590    0.166667         0.000000         0.000000   \n",
       "189079  PRD0168-OL97602    0.000000         0.001581         0.000242   \n",
       "189080  PRD0168-OL97615    0.333333         0.001319         0.000202   \n",
       "189081  PRD0168-OL97618    0.333333         0.003323         0.000505   \n",
       "\n",
       "        sales_indicator  scheme_amount_perproduct  probablity  \n",
       "0                     1                  0.001560    0.807117  \n",
       "1                     0                  0.001560    0.298748  \n",
       "2                     0                  0.001559    0.298690  \n",
       "3                     1                  0.001560    0.950099  \n",
       "4                     1                  0.001560    0.899377  \n",
       "...                 ...                       ...         ...  \n",
       "189077                1                  0.001560    0.298657  \n",
       "189078                0                  0.001560    0.298999  \n",
       "189079                0                  0.001560    0.165792  \n",
       "189080                1                  0.001560    0.477312  \n",
       "189081                0                  0.001560    0.476894  \n",
       "\n",
       "[189082 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_unseen = test_final[['frequencym','sales_value_avg','scheme_amount_perproduct']]\n",
    "y_test_unseen = test_final['sales_indicator']\n",
    "print(X_test_unseen.shape,y_test_unseen.shape)\n",
    "probs = loaded_model.predict_proba(X_test_unseen)\n",
    "test_final['probablity']=probs[:,1]\n",
    "y_pred = (probs[:,1]>=0.4).astype(int)\n",
    "test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11704ebf-2a0a-42c1-8129-75271561308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>frequencym</th>\n",
       "      <th>sales_value_avg</th>\n",
       "      <th>sales_units_avg</th>\n",
       "      <th>sales_indicator</th>\n",
       "      <th>scheme_amount_perproduct</th>\n",
       "      <th>probablity</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD0002-OL10330</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.807117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD0002-OL10346</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD0002-OL10347</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.298690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD0002-OL10358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.950099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD0002-OL10386</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.899377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189077</th>\n",
       "      <td>PRD0168-OL97586</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189078</th>\n",
       "      <td>PRD0168-OL97590</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.298999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189079</th>\n",
       "      <td>PRD0168-OL97602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.165792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189080</th>\n",
       "      <td>PRD0168-OL97615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.477312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189081</th>\n",
       "      <td>PRD0168-OL97618</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.476894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189082 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id  frequencym  sales_value_avg  sales_units_avg  \\\n",
       "0       PRD0002-OL10330    0.666667         0.004323         0.000404   \n",
       "1       PRD0002-OL10346    0.166667         0.001430         0.000135   \n",
       "2       PRD0002-OL10347    0.166667         0.001767         0.000168   \n",
       "3       PRD0002-OL10358    1.000000         0.015771         0.001481   \n",
       "4       PRD0002-OL10386    0.833333         0.008417         0.000791   \n",
       "...                 ...         ...              ...              ...   \n",
       "189077  PRD0168-OL97586    0.166667         0.001948         0.000303   \n",
       "189078  PRD0168-OL97590    0.166667         0.000000         0.000000   \n",
       "189079  PRD0168-OL97602    0.000000         0.001581         0.000242   \n",
       "189080  PRD0168-OL97615    0.333333         0.001319         0.000202   \n",
       "189081  PRD0168-OL97618    0.333333         0.003323         0.000505   \n",
       "\n",
       "        sales_indicator  scheme_amount_perproduct  probablity  prediction  \n",
       "0                     1                  0.001560    0.807117           1  \n",
       "1                     0                  0.001560    0.298748           0  \n",
       "2                     0                  0.001559    0.298690           0  \n",
       "3                     1                  0.001560    0.950099           1  \n",
       "4                     1                  0.001560    0.899377           1  \n",
       "...                 ...                       ...         ...         ...  \n",
       "189077                1                  0.001560    0.298657           0  \n",
       "189078                0                  0.001560    0.298999           0  \n",
       "189079                0                  0.001560    0.165792           0  \n",
       "189080                1                  0.001560    0.477312           1  \n",
       "189081                0                  0.001560    0.476894           1  \n",
       "\n",
       "[189082 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final['prediction']= test_final['probablity'].apply(lambda x: 1  if x>=0.3 else 0)\n",
    "test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a35948-41d5-4edc-901b-3acc338e1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77    124905\n",
      "           1       0.56      0.61      0.58     64177\n",
      "\n",
      "    accuracy                           0.70    189082\n",
      "   macro avg       0.67      0.68      0.68    189082\n",
      "weighted avg       0.71      0.70      0.71    189082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_final_static = test_final.copy()\n",
    "print(classification_report(test_final['sales_indicator'],test_final['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b30b850-92a8-460a-81ba-9991bdb9ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.reset_index(drop=True)\n",
    "test_final['OOS'] = test_final['probablity'].apply(lambda x:1 if x>0.3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d45c1ec-fca0-4069-bd57-f087347529ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "soq_master = master_data.groupby('unique_id').agg({'sales_units':'sum','mnth_code':'nunique'})\n",
    "soq_master['SOQ'] = soq_master['sales_units']/soq_master['mnth_code']\n",
    "soq_master.reset_index()\n",
    "final_reco = pd.merge(soq_master,test_final,on='unique_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0969f141-fa63-4122-b1a8-1ee94c132094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>SOQ</th>\n",
       "      <th>OOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD0002-OL10330</td>\n",
       "      <td>1</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD0002-OL10346</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD0002-OL10347</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD0002-OL10358</td>\n",
       "      <td>1</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD0002-OL10386</td>\n",
       "      <td>1</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id  prediction       SOQ  OOS\n",
       "0  PRD0002-OL10330           1  2.714286    1\n",
       "1  PRD0002-OL10346           0  1.500000    0\n",
       "2  PRD0002-OL10347           0  1.250000    0\n",
       "3  PRD0002-OL10358           1  7.166667    1\n",
       "4  PRD0002-OL10386           1  4.090909    1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reco = final_reco[['unique_id','prediction','SOQ','OOS']]\n",
    "final_reco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f93ee0-c9cc-4180-8e69-6b151ab6fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_reco = final_reco.copy()\n",
    "ms_reco.columns = ['unique_id', 'ms_flag', 'soq', 'oos_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d7d3619-6539-42e6-bef1-256839a60946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03fbc4f9-3c9c-4849-bcaf-26a4a97e31ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ms_flag</th>\n",
       "      <th>soq</th>\n",
       "      <th>oos_flag</th>\n",
       "      <th>product</th>\n",
       "      <th>outlet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD0002-OL10330</td>\n",
       "      <td>1</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>PRD0002</td>\n",
       "      <td>OL10330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD0002-OL10346</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>PRD0002</td>\n",
       "      <td>OL10346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD0002-OL10347</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>PRD0002</td>\n",
       "      <td>OL10347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD0002-OL10358</td>\n",
       "      <td>1</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>PRD0002</td>\n",
       "      <td>OL10358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD0002-OL10386</td>\n",
       "      <td>1</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>PRD0002</td>\n",
       "      <td>OL10386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id  ms_flag       soq  oos_flag  product   outlet\n",
       "0  PRD0002-OL10330        1  2.714286         1  PRD0002  OL10330\n",
       "1  PRD0002-OL10346        0  1.500000         0  PRD0002  OL10346\n",
       "2  PRD0002-OL10347        0  1.250000         0  PRD0002  OL10347\n",
       "3  PRD0002-OL10358        1  7.166667         1  PRD0002  OL10358\n",
       "4  PRD0002-OL10386        1  4.090909         1  PRD0002  OL10386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_reco[['product', 'outlet']] = ms_reco['unique_id'].str.split('-', expand=True)\n",
    "ms_reco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfda7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_reco=session.createDataFrame(\n",
    "        ms_reco.values.tolist(),\n",
    "        schema=ms_reco.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1276ec-54f7-4dd8-8d3f-2b4c730ec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_reco.write.mode(\"overwrite\").save_as_table(\"ASSORTMENT_PLANNING.PUBLIC.PREDICTION_TABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cb5db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'payload': {'unique_id': 'PRD0002-OL12565', 'frequencym': 0.0, 'sales_value_avg': 0.0, 'sales_units_avg': 0.0, 'sales_indicator': 0, 'scheme_amount_perproduct': 0.001559427, 'probablity': 0.16597489859674663, 'prediction': 0, 'OOS': 0}}\n"
     ]
    }
   ],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":X_test_unseen.head(1).to_json()}\n",
    "print({'payload': payload})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "562f5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(eval(payload))\n",
    "    prediction = pd.DataFrame(model.predict(data))\n",
    "    return prediction.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "588937ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\":{\"0\":1.0}}\n"
     ]
    }
   ],
   "source": [
    "print(score(loaded_model, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e60ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae7fc064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating build time metrics\n",
      "\n",
      "Progress: ██████████████████████████████████████████████████████████████████████ 100.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aca0c87985d4595ab3eebe67a93336a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = register_model(loaded_model, \n",
    "               score, \n",
    "               name=\"Assortment_Planning_Prediction\", \n",
    "               description=\"prediction of assortment across retailers by product\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"regression\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred, \n",
    "               prob=probs, \n",
    "               features=X_train.columns,\n",
    "               labels=[0,1],\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True, \n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_test.tolist(),\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               target_names=['No Failure',' or Failure'],\n",
    "               kyd=True, kyd_score = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
