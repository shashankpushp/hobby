{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6844525",
   "metadata": {},
   "source": [
    "# Run using AWS_BedRock_Anthropic_Claude_V2 Notebook template (Python 3.9 with numpy == 1.24.0 and refractml==1.0.3, Medium Container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8283c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 3.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.20\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting tqdm\n",
      "  Using cached https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl\n",
      "Collecting aiohttp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/97/d042349afcad79d7c813b07e34cb3a6f0024b4faf07346509b115fe19f97/aiohttp-3.8.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 21.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 54.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/3d/785761e64dc90fda6feb9bd0459dc55ebe282a7d4564642a4a8ee277e0c0/yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 51.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Collecting frozenlist>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/03/7dec2e257bd173b5ca1f74477863b97d322149f6f0284d7decead8c5ceeb/frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 77.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl\n",
      "Collecting attrs>=17.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/eb/fcb708c7bf5056045e9e98f62b93bd7467eb718b0202e7698eb11d66416c/attrs-23.1.0-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/48/2750fd3ace4d778b4e1f7110db3ad637906de3496abc9c450ce726b97337/multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 58.1MB/s eta 0:00:01\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.32.0 has requirement urllib3<1.27,>=1.25.4; python_version < \"3.10\", but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: certifi, charset-normalizer, idna, urllib3, requests, tqdm, multidict, yarl, frozenlist, aiosignal, async-timeout, attrs, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.3.2 frozenlist-1.4.0 idna-3.4 multidict-6.0.4 openai-0.28.1 requests-2.31.0 tqdm-4.66.1 urllib3-2.1.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2023.7.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm-4.66.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ce214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_KEY=openai_key\n",
    "AZURE_OPENAI_ENDPOINT=\"https://gear.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29960a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = AZURE_OPENAI_KEY\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-07-01-preview' # this might change in the future\n",
    "deployment_name='gpt-35-turbo' #This will correspond to the custom name you chose for your deployment when you deployed a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f75cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_text = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},{\"role\":\"user\",\"content\":\"who is President of India ?\"},{\"role\":\"assistant\",\"content\":\"As of September 2021, the Prime Minister of India is Narendra Modi.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c25e1de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://gear.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview\n",
      "DEBUG:openai:api_version=2023-07-01-preview data='{\"messages\": [{\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"}, {\"role\": \"user\", \"content\": \"who is President of India ?\"}, {\"role\": \"assistant\", \"content\": \"As of September 2021, the Prime Minister of India is Narendra Modi.\"}], \"temperature\": 0.7, \"max_tokens\": 800, \"top_p\": 0.95, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"stop\": null}' message='Post details'\n",
      "DEBUG:urllib3.connectionpool:https://gear.openai.azure.com:443 \"POST //openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview HTTP/1.1\" 200 870\n",
      "DEBUG:openai:message='OpenAI API response' path=https://gear.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview processing_ms=None request_id=8df5d642-c9a1-448f-9df8-6a196fcfb265 response_code=200\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  engine=\"gpt-35-turbo\",\n",
    "  messages = message_text,\n",
    "  temperature=0.7,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4a3ac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8L7I6Lsw60DUeuR2757NnsbKBdrMA at 0x7ff66877ad60> JSON: {\n",
       "  \"id\": \"chatcmpl-8L7I6Lsw60DUeuR2757NnsbKBdrMA\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1700043606,\n",
       "  \"model\": \"gpt-35-turbo\",\n",
       "  \"prompt_filter_results\": [\n",
       "    {\n",
       "      \"prompt_index\": 0,\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Apologies for the confusion in my previous response. As of September 2021, the President of India is Ram Nath Kovind.\"\n",
       "      },\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 48,\n",
       "    \"completion_tokens\": 27,\n",
       "    \"total_tokens\": 75\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9337a426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apologies for the confusion in my previous response. As of September 2021, the President of India is Ram Nath Kovind.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion['choices'][0]['message']['content'].replace('\\n', '').replace(' .', '.').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fc73d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "\n",
    "# new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c38bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Registration\n",
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        import openai\n",
    "        \n",
    "        openai.api_key = self.AZURE_OPENAI_KEY\n",
    "        openai.api_base = \"https://gear.openai.azure.com/\" #self.AZURE_OPENAI_ENDPOINT # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "        openai.api_type = 'azure'\n",
    "        openai.api_version = '2023-07-01-preview' # this might change in the future\n",
    "        deployment_name='gpt-35-turbo'\n",
    "    \n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[Input data, ..]. It could be:\n",
    "               A List Mapping of All Value Can Be one of : \n",
    "                   - List[ [Feature_Value1, Feature_Value2, ...], [...] ]\n",
    "                   - List[numpy.array(), numpy.array(), ...]\n",
    "                   - List[tf.Tensor, tf.Tensor, tf.Tensor, ...]\n",
    "                   - List[ SingleSample, SingleSample]\n",
    "                   \n",
    "        :return: (n_inputs, payload's)\n",
    "        \n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (1, raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        # All preprocessing step must occur in this section\n",
    "        # Takes Single Sample -> Returns Single Sample\n",
    "        \n",
    "        # Not Doing Any Preprocessing Hence Returned payload\n",
    "        #print(\"payload is \", payload)\n",
    "        return payload\n",
    "\n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      pre_processed_input \n",
    "                      ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        #self.message_text \n",
    "        conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "        conversation.append({\"role\": \"user\", \"content\": pre_processed_input})\n",
    "        #print (conversation)\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-35-turbo\",\n",
    "            messages = conversation,\n",
    "            temperature=0.7,\n",
    "            max_tokens=800,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None\n",
    "        )\n",
    "        \n",
    "        #print (completion)\n",
    "        return completion['choices'][0]['message']['content'].replace('\\n', '').replace(' .', '.').strip()\n",
    "\n",
    "\n",
    "    class Meta:    \n",
    "        # List of Callables() can be attached For Calling After AnSd Before Scoring\n",
    "        def __init__(self):\n",
    "            self.name = \"Pre Hooked Me !\"\n",
    "            self.pre_call_hooks.append(self.print_)\n",
    "        def print_(self):\n",
    "            print(self.name)\n",
    "        pre_call_hooks = []\n",
    "        post_call_hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c68ea891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'payload': 'Who is the Defence Minister of India'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who is the Defence Minister of India\"\n",
    "import requests\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":prompt}\n",
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5501f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Hooked Me !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://gear.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview\n",
      "DEBUG:openai:api_version=2023-07-01-preview data='{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who is the Defence Minister of India\"}], \"temperature\": 0.7, \"max_tokens\": 800, \"top_p\": 0.95, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"stop\": null}' message='Post details'\n",
      "DEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): gear.openai.azure.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://gear.openai.azure.com:443 \"POST //openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview HTTP/1.1\" 200 820\n",
      "DEBUG:openai:message='OpenAI API response' path=https://gear.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview processing_ms=None request_id=50418006-b5d0-46ea-b89f-43b1c65908ec response_code=200\n"
     ]
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "model_predictions = score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b91c65d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2021, the Defence Minister of India is Rajnath Singh.\n"
     ]
    }
   ],
   "source": [
    "print(model_predictions[0].score_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67dfabfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 2041\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/32f760e2-9efb-49fb-9559-1cb279d717c9 HTTP/1.1\" 200 2034\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/32f760e2-9efb-49fb-9559-1cb279d717c9 HTTP/1.1\" 200 2034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e274a2021e3c44b6ba5af1accc81a761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(None,\n",
    "               ScoreTemplateExample,\n",
    "               \"Azure_OpenAI_GPT35_Turbo\",\n",
    "               \"Azure_OpenAI_GPT35_Turbo\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"pip install openai==0.28.1\",\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
