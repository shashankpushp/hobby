{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab10dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cloudpickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "from refractio import get_local_dataframe, get_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(exp_details, tpot_config, generations, population_size, cv, random_state, verbosity):\n",
    "    \"\"\"\n",
    "    exp_details: {\n",
    "        name: exp_name\n",
    "        id: exp_id\n",
    "        description: exp_description\n",
    "        dataset: exp_dataset\n",
    "        target_column: exp_target_column\n",
    "        algo_details: None\n",
    "    }\n",
    "    tpot_config: dict\n",
    "    generations: 0.5\n",
    "    population_size: 0.5\n",
    "    cv: 5\n",
    "    random_state: 42\n",
    "    verbosity: 2\n",
    "    \"\"\"\n",
    " # Tracking URI set\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URL\", \"http://mlflow-server\"))\n",
    "\n",
    "    # Setting experiment name\n",
    "    mlflow.set_experiment(exp_details.get(\"name\", \"sample_experiment\"))\n",
    "\n",
    "    # Adding description to the experiment\n",
    "    tags = {'mlflow.note.content': exp_details.get(\"description\", \"sample_description\")}\n",
    "\n",
    "# Reading input data\n",
    "    try:\n",
    "        if exp_details.get(\"dataset\").split(\".\")[-1].lower() in [\"csv\", \"tsv\", \"xlsx\", \"xls\"]:\n",
    "            # Read the input data file from /data mount attached to this notebook pod\n",
    "            input_file = \"/data/\" + exp_details.get(\"dataset\")\n",
    "            data = get_local_dataframe(input_file)\n",
    "        else:\n",
    "            # Input data is a dataset\n",
    "            data = get_dataframe(exp_details.get(\"dataset\"))\n",
    "            # Adding this to log input data in mlflow\n",
    "            input_file = '/tmp/input_data.csv'\n",
    "            data.to_csv(input_file, index=False)            \n",
    "    except Exception as ex:\n",
    "        print(f\"Unable to read input dataset.\\nError: {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97214aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-14-2bb48d7433c6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Reading input data\n",
    "    try:\n",
    "        if exp_details.get(\"dataset\").split(\".\")[-1].lower() in [\"csv\", \"tsv\", \"xlsx\", \"xls\"]:\n",
    "            # Read the input data file from /data mount attached to this notebook pod\n",
    "            input_file = \"/data/\" + exp_details.get(\"dataset\")\n",
    "            data = get_local_dataframe(input_file)\n",
    "        else:\n",
    "            # Input data is a dataset\n",
    "            data = get_dataframe(exp_details.get(\"dataset\"))\n",
    "            # Adding this to log input data in mlflow\n",
    "            input_file = '/tmp/input_data.csv'\n",
    "            data.to_csv(input_file, index=False)            \n",
    "    except Exception as ex:\n",
    "        print(f\"Unable to read input dataset.\\nError: {ex}\")\n",
    "        \n",
    "        \n",
    "    # Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "    data = data.fillna(method='pad')  # Filling null values with the previous ones\n",
    "    data = data.fillna(method='bfill')  # Filling null value with the next ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3f025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
